{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a62da6",
   "metadata": {},
   "source": [
    "### Check avaiavailable GPU and import MovrNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80ea641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: []\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import math\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs Available:\", gpus)\n",
    "\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48efa5",
   "metadata": {},
   "source": [
    "### detect poes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193ae3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pose(frame,dict_list, model=movenet, input_size=256, debug=True):\n",
    "\n",
    "    if frame is None:\n",
    "        if debug: print(\"detect_pose: input frame is None\")\n",
    "        return []\n",
    "\n",
    "    # ensure color order: OpenCV gives BGR, MoveNet expects RGB-like ordering\n",
    "    try:\n",
    "        if frame.ndim == 2:  # grayscale -> convert to 3 channels\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    except Exception as e:\n",
    "        if debug: print(\"detect_pose: color conversion failed:\", e)\n",
    "        return []\n",
    "\n",
    "    # Resize to model input size\n",
    "    img_resized = cv2.resize(img_rgb, (input_size, input_size))\n",
    "\n",
    "    # MoveNet expects integer pixel values (0-255). Use int32.\n",
    "    img_int = img_resized.astype(np.int32)\n",
    "    input_tensor = tf.expand_dims(tf.convert_to_tensor(img_int, dtype=tf.int32), axis=0)  # shape [1,H,W,3]\n",
    "\n",
    "    # Call model and be defensive about errors\n",
    "    try:\n",
    "        outputs = model(input=input_tensor)\n",
    "    except Exception as e:\n",
    "        if debug: print(\"detect_pose: model call failed:\", e)\n",
    "        return []\n",
    "\n",
    "    # Look for expected output key\n",
    "    if 'output_0' not in outputs:\n",
    "        if debug:\n",
    "            print(\"detect_pose: unexpected output keys from model:\", list(outputs.keys()))\n",
    "        return []\n",
    "\n",
    "    keypoints_with_scores = outputs['output_0'].numpy()  # expected shape [1, 1, 17, 3]\n",
    "\n",
    "    # guard against weird shapes\n",
    "    if keypoints_with_scores.ndim != 4 or keypoints_with_scores.shape[2] != 17:\n",
    "        if debug: print(\"detect_pose: unexpected keypoints shape\")\n",
    "        return []\n",
    "    kps = keypoints_with_scores[0][0]\n",
    "    last_kps = [row[:2] for row in kps]\n",
    "    if dict_list==0 :\n",
    "        return kps\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        scores = kps[:,2]\n",
    "\n",
    "    keypoints = []\n",
    "    for kp in kps:\n",
    "        y, x, score = float(kp[0]), float(kp[1]), float(kp[2])\n",
    "        keypoints.append({'x': x, 'y': y, 'score': score})\n",
    "\n",
    "\n",
    "    if dict_list==1 :\n",
    "        return keypoints\n",
    "\n",
    "\n",
    "def draw_keypoints(frame, keypoints, threshold=0.3):\n",
    "    \"\"\"Draw small circles on `frame` for keypoints with score >= threshold.\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        if kp['score'] >= threshold:\n",
    "            cx = int(kp['x'] * w)\n",
    "            cy = int(kp['y'] * h)\n",
    "            cv2.circle(frame, (cx, cy), 4, (0,255,0), -1)\n",
    "            # optional: label index\n",
    "            cv2.putText(frame, str(i), (cx+5, cy+5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0,255,0), 1)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4080e",
   "metadata": {},
   "source": [
    "### predict standing angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526a4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOSE = 0\n",
    "LEFT_SHOULDER = 5\n",
    "RIGHT_SHOULDER = 6\n",
    "\n",
    "def calculate_person_angle(keypoints_cam1, keypoints_cam2, confidence_threshold=0.3):\n",
    "    try:\n",
    "        required_indices = [NOSE, LEFT_SHOULDER, RIGHT_SHOULDER]\n",
    "        max_index = max(required_indices)\n",
    "        if (keypoints_cam1 is None or len(keypoints_cam1) <= max_index or\n",
    "            keypoints_cam2 is None or len(keypoints_cam2) <= max_index):\n",
    "            print(\"Error: Keypoint list is None, missing, or too short. A camera may have failed to detect a pose.\")\n",
    "            return None\n",
    "\n",
    "        # Get keypoints from Camera 1\n",
    "        ls1 = keypoints_cam1[LEFT_SHOULDER]\n",
    "        rs1 = keypoints_cam1[RIGHT_SHOULDER]\n",
    "        nose1 = keypoints_cam1[NOSE]\n",
    "\n",
    "        # Get keypoints from Camera 2\n",
    "        ls2 = keypoints_cam2[LEFT_SHOULDER]\n",
    "        rs2 = keypoints_cam2[RIGHT_SHOULDER]\n",
    "        nose2 = keypoints_cam2[NOSE]\n",
    "\n",
    "        # Check confidence scores\n",
    "        if not all(kp['score'] > confidence_threshold for kp in [ls1, rs1, nose1, ls2, rs2, nose2]):\n",
    "            return \"not accurate\"\n",
    "        x_l1, x_r1, x_n1 = ls1['x'], rs1['x'], nose1['x']\n",
    "        x_l2, x_r2, x_n2 = ls2['x'], rs2['x'], nose2['x']\n",
    "        dx = x_l1 - x_r1\n",
    "        dz = x_l2 - x_r2\n",
    "        mid_shoulder_x = (x_l1 + x_r1) / 2\n",
    "        mid_shoulder_z = (x_l2 + x_r2) / 2\n",
    "        nose_dir_vec_x = x_n1 - mid_shoulder_x\n",
    "        nose_dir_vec_z = x_n2 - mid_shoulder_z\n",
    "        p1_x, p1_z = -dz, dx\n",
    "        dot_product = (p1_x * nose_dir_vec_x) + (p1_z * nose_dir_vec_z)\n",
    "\n",
    "        if dot_product > 0:\n",
    "            facing_vec_x, facing_vec_z = p1_x, p1_z\n",
    "        else:\n",
    "            facing_vec_x, facing_vec_z = dz, -dx\n",
    "        angle_rad = math.atan2(facing_vec_x, facing_vec_z)\n",
    "        angle_deg = math.degrees(angle_rad)\n",
    "\n",
    "        return angle_deg\n",
    "\n",
    "    except (TypeError) as e:\n",
    "        print(f\"Error: Invalid keypoint data format. {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a883352",
   "metadata": {},
   "source": [
    "### cameras prepairing and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4bed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_bars_auto(frame, thresh_value=16):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(gray, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(mask)\n",
    "    if coords is None:\n",
    "        return frame\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    return frame[y:y+h, x:x+w]\n",
    "\n",
    "def rotate_if_needed(frame, rotate_code=None):\n",
    "    if rotate_code is None:\n",
    "        return frame\n",
    "    return cv2.rotate(frame, rotate_code)\n",
    "\n",
    "def resize_and_center_crop_fill(img, target_size=(640, 480)):\n",
    "    target_w, target_h = target_size\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if (w, h) == (target_w, target_h):\n",
    "        return img\n",
    "\n",
    "    scale = max(target_w / w, target_h / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    x = (new_w - target_w) // 2\n",
    "    y = (new_h - target_h) // 2\n",
    "    cropped = resized[y:y+target_h, x:x+target_w]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b4b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap0 = cv2.VideoCapture(0)\n",
    "cap1 = cv2.VideoCapture(1)\n",
    "\n",
    "while cap0.isOpened() and cap1.isOpened():\n",
    "    ret0, frame0 = cap0.read()\n",
    "    ret1, frame1 = cap1.read()\n",
    "    frame1 = cv2.rotate(frame1, cv2.ROTATE_90_CLOCKWISE)\n",
    "    frame1 = remove_black_bars_auto(frame1, thresh_value=16)\n",
    "    frame1 = resize_and_center_crop_fill(frame1, target_size=(640, 480))\n",
    "\n",
    "    keypoints1 = detect_pose(frame0,0)\n",
    "    keypoints2 = detect_pose(frame1,0)\n",
    "    kpts0 = []\n",
    "    kpts1 = []\n",
    "\n",
    "    for kp in keypoints1:\n",
    "        y, x, score = float(kp[0]), float(kp[1]), float(kp[2])\n",
    "        kpts0.append({'x': x, 'y': y, 'score': score})\n",
    "\n",
    "    for kp in keypoints2:\n",
    "        y, x, score = float(kp[0]), float(kp[1]), float(kp[2])\n",
    "        kpts1.append({'x': x, 'y': y, 'score': score})\n",
    "\n",
    "    frame0 = draw_keypoints(frame0, kpts0)\n",
    "    frame1 = draw_keypoints(frame1, kpts1)\n",
    "\n",
    "\n",
    "    degree = calculate_person_angle(kpts0, kpts1) if calculate_person_angle(kpts0, kpts1) == \"not accurate\" else (f\"deg:{calculate_person_angle(kpts0, kpts1):.1f}\")\n",
    "\n",
    "    cv2.putText(frame0, degree, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.putText(frame1, degree, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    combined = cv2.hconcat([frame0, frame1])\n",
    "\n",
    "    cv2.imshow(\"Combined\", combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap0.release()\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
